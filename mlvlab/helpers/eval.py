# mlvlab/evaluation/eval.py

from __future__ import annotations

import os
from pathlib import Path
from typing import Callable, Optional
import time
import shutil
import sys

import gymnasium as gym
import imageio  # Necesario para la grabaci√≥n manual
from rich.progress import track
from contextlib import contextmanager


@contextmanager
def suppress_stderr():
    """Un gestor de contexto para suprimir temporalmente la salida a stderr."""
    with open(os.devnull, "w") as devnull:
        old_stderr = sys.stderr
        sys.stderr = devnull
        try:
            yield
        finally:
            sys.stderr = old_stderr


# Asumiendo que merge_videos_with_counter est√° disponible, aunque no lo usaremos en este flujo
try:
    from .video import merge_videos_with_counter
except ImportError:
    def merge_videos_with_counter(*args, **kwargs):
        print("‚ö†Ô∏è Utilidad de v√≠deo no encontrada.")
        return False


def evaluate_with_optional_recording(
    env_id: str,
    run_dir: Path,
    episodes: int,
    agent_builder: Callable[[gym.Env], object],
    seed: Optional[int] = None,
    record: bool = False,
    speed: float = 1.0,
) -> Optional[Path]:
    """
    Eval√∫a un agente y, si record=True, graba un v√≠deo de la evaluaci√≥n de forma manual
    para asegurar la compatibilidad con renderers cinem√°ticos dependientes del tiempo.
    """
    final_video_path = run_dir / "evaluation.mp4"

    # --- L√ìGICA DE RENDERIZADO Y GRABACI√ìN RECTIFICADA ---

    render_mode = "human" if not record else "rgb_array"
    env = gym.make(env_id, render_mode=render_mode)

    # Activar el modo debug si est√° disponible, para visualizaciones extra
    if hasattr(env.unwrapped, "debug_mode"):
        env.unwrapped.debug_mode = True

    # Configuraci√≥n de respawn determinista para una evaluaci√≥n consistente
    if hasattr(env.unwrapped, "set_respawn_unseeded"):
        try:
            env.unwrapped.set_respawn_unseeded(False)
            print("‚ÑπÔ∏è  Configurado respawn determinista (seeded) para evaluaci√≥n.")
        except Exception as e:
            print(
                f"‚ö†Ô∏è Advertencia: No se pudo configurar el respawn determinista: {e}")

    # Construcci√≥n del agente
    agent = agent_builder(env)

    # Carga del estado del agente (p.ej., Tabla Q)
    agent_file = run_dir / "q_table.npy"  # Asumiendo un nombre est√°ndar
    if hasattr(agent, "load") and agent_file.exists():
        try:
            agent.load(str(agent_file))
            print(f"üß† Cargado estado del agente desde {agent_file}.")
        except Exception as e:
            print(f"‚ö†Ô∏è No se pudo cargar el estado del agente: {e}")

    # Forzar modo explotaci√≥n (sin acciones aleatorias)
    if hasattr(agent, "epsilon"):
        setattr(agent, "epsilon", 0.0)

    # --- BUCLE DE EVALUACI√ìN ---

    frames = []  # Lista para guardar los fotogramas si estamos grabando

    for ep in track(range(episodes), description="Evaluando..."):
        current_seed = seed if ep == 0 else None
        obs, info = env.reset(seed=current_seed)

        terminated, truncated = False, False
        while not (terminated or truncated):

            # Pasar datos de renderizado al entorno si es necesario (p.ej. Q-Table)
            q_table = getattr(agent, "q_table", None)
            if q_table is not None and hasattr(env.unwrapped, "set_render_data"):
                env.unwrapped.set_render_data(q_table=q_table)

            action = agent.act(obs)
            obs, reward, terminated, truncated, info = env.step(action)

            if record:
                # Grabaci√≥n manual del frame
                frame = env.render()
                if frame is not None:
                    frames.append(frame)
            else:
                # Renderizado en tiempo real para el modo humano
                env.render()

            # PAUSA CRUCIAL para dar tiempo al renderer cinem√°tico
            target_fps = env.metadata.get("render_fps", 60)
            effective_speed = max(speed, 0.01)
            delay = (1.0 / target_fps) / effective_speed
            time.sleep(delay)

    # --- GRABACI√ìN DE LA ESCENA FINAL CINEM√ÅTICA (SOLO EN MODO RECORD) ---
    if record:
        print("Grabando escena final cinem√°tica...")
        # Grabamos durante 0.5 segundos extra para capturar la animaci√≥n completa del renderer
        num_final_frames = int(env.metadata.get("render_fps", 60) * 0.5)
        for _ in range(num_final_frames):
            frame = env.render()
            if frame is not None:
                frames.append(frame)
            time.sleep(1/env.metadata.get("render_fps", 60))

        # Guardar el v√≠deo usando imageio
        if frames:
            effective_speed = max(speed, 0.01)
            playback_fps = target_fps * effective_speed

            print(
                f"Guardando v√≠deo a {playback_fps:.2f} FPS (velocidad x{speed})...")
            try:
                # Aqu√≠ podr√≠as usar tu supresor de warnings si quieres
                imageio.mimsave(str(final_video_path),
                                frames, fps=playback_fps)
                print(
                    f"‚úÖ Evaluaci√≥n completada. V√≠deo guardado en: {final_video_path}")
            except Exception as e:
                print(f"‚ùå Error al guardar el v√≠deo con imageio: {e}")
                final_video_path = None
        else:
            print("‚ö†Ô∏è No se generaron frames para el v√≠deo.")
            final_video_path = None

    env.close()

    if not record:
        print("‚úÖ Evaluaci√≥n completada en modo interactivo.")
        return None

    return final_video_path
